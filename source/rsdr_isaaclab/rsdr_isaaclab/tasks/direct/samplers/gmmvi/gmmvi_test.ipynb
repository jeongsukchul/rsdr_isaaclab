{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']= '2'\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']= 'false'\n",
    "# os.environ['MUJOCO_GL']= 'egl'\n",
    "# os.environ['EGL_DEVICE_ID'] = '2' \n",
    "# print(\"CUDA_VISIBLE_DEVICES =\", os.environ.get('CUDA_VISIBLE_DEVICES'))\n",
    "# import jax\n",
    "# print(\"JAX devices:\", jax.devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from learning.module.target_examples.funnel import Funnel\n",
    "from learning.module.target_examples.gmm40 import GMM40\n",
    "import functools\n",
    "import chex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup GMMVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".network import create_gmm_network_and_state\n",
    ".network import GMMTrainingState\n",
    "from learning.module.target_examples.student_t_mixture import StudentTMixtureModel\n",
    "dim=20\n",
    "\n",
    "# target = StudentTMixtureModel(dim=dim, sample_bounds=[-30., 30.], num_components=40)\n",
    "target = GMM40(dim=dim)\n",
    "# target = Funnel(dim=dim, sample_bounds=[-30, 30])\n",
    "# low = jnp.ones(dim)*-10\n",
    "# low = jnp.array([-30,-30])\n",
    "low = jnp.ones(dim) * (-target._plot_bound)\n",
    "# high = jnp.ones(dim)* 5\n",
    "high = jnp.ones(dim) * (target._plot_bound)\n",
    "\n",
    "\n",
    "key= jax.random.PRNGKey(0)\n",
    "num_envs=1024\n",
    "batch_size=1024\n",
    "bound_info = low, high\n",
    "initial_train_state, gmm_network = create_gmm_network_and_state(dim, num_envs, batch_size, key, prior_scale=.1, bound_info=(low,high))\n",
    "# Sampling:\n",
    "contexts, logp = gmm_network.model.sample(initial_train_state.model_state.gmm_state, key, 1000)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist2d(contexts[:, 0], contexts[:, 1], bins=100, range=[[low[0], high[0]], [low[1], high[1]]])\n",
    "plt.title(\"Initial GMM samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.partial(jax.jit, static_argnames=['target_log_prob_fn'])\n",
    "def gather_samples(train_state: GMMTrainingState, key: chex.Array, target_log_prob_fn):\n",
    "    def get_target_grads(samples):\n",
    "        return jax.vmap(jax.value_and_grad(target_log_prob_fn))(samples)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_samples, mapping = gmm_network.sample_selector.select_samples(train_state.model_state, subkey)\n",
    "    # new_samples, mapping = gmm_network.model.sample(train_state.model_state.gmm_state, subkey, num_envs)\n",
    "    new_target_lnpdfs, new_target_grads = get_target_grads(new_samples)\n",
    "    # new_target_lnpdfs = target_log_prob_fn(new_samples)\n",
    "    # new_target_grads = jnp.zeros_like(new_samples)\n",
    "    new_sample_db_state = gmm_network.sample_selector.save_samples(train_state.model_state, train_state.sample_db_state, new_samples, new_target_lnpdfs, new_target_grads, mapping)\n",
    "    return GMMTrainingState(temperature=train_state.temperature,\n",
    "                        model_state=train_state.model_state,\n",
    "                        component_adaptation_state=train_state.component_adaptation_state,\n",
    "                        num_updates=train_state.num_updates,\n",
    "                        sample_db_state=new_sample_db_state,\n",
    "                        weight_stepsize=train_state.weight_stepsize)\n",
    "@functools.partial(jax.jit, static_argnames=['target_log_prob_fn'])\n",
    "def train_iter(train_state: GMMTrainingState, key: chex.Array, target_log_prob_fn):\n",
    "    def get_target_grads(samples):\n",
    "        return jax.vmap(jax.value_and_grad(target_log_prob_fn))(samples)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_samples, mapping = gmm_network.sample_selector.select_samples(train_state.model_state,\n",
    "                                        subkey)\n",
    "    # new_samples, mapping = gmm_network.model.sample(train_state.model_state.gmm_state, subkey, num_envs)\n",
    "    new_target_lnpdfs, new_target_grads = get_target_grads(new_samples)\n",
    "    # new_target_lnpdfs = target_log_prob_fn(new_samples)\n",
    "    # new_target_grads = jnp.zeros_like(new_samples)\n",
    "    new_sample_db_state = gmm_network.sample_selector.save_samples(train_state.model_state, train_state.sample_db_state, new_samples, new_target_lnpdfs, new_target_grads, mapping)\n",
    "    samples, mapping, sample_dist_densities, target_lnpdfs, target_lnpdf_grads = \\\n",
    "        gmm_network.sample_selector.select_train_datas(new_sample_db_state)\n",
    "\n",
    "    new_component_stepsizes = gmm_network.component_stepsize_fn(train_state.model_state)\n",
    "    new_model_state = gmm_network.model.update_stepsizes(train_state.model_state, new_component_stepsizes)\n",
    "    # expected_hessian_neg, expected_grad_neg = gmm_network.ng_estimator(new_model_state,\n",
    "    #                                                         samples,\n",
    "    #                                                         sample_dist_densities,\n",
    "    #                                                         target_lnpdfs,\n",
    "    #                                                         target_lnpdf_grads)\n",
    "    expected_hessian_neg, expected_grad_neg = gmm_network.more_ng_estimator(new_model_state,\n",
    "                                                            samples,\n",
    "                                                            sample_dist_densities,\n",
    "                                                            target_lnpdfs,\n",
    "                                                            target_lnpdf_grads)\n",
    "    new_model_state = gmm_network.component_updater(new_model_state,\n",
    "                                    expected_hessian_neg,\n",
    "                                    expected_grad_neg,\n",
    "                                    new_model_state.stepsizes)\n",
    "\n",
    "    new_model_state = gmm_network.weight_updater(new_model_state, samples, sample_dist_densities, target_lnpdfs,\n",
    "                                                    train_state.weight_stepsize)\n",
    "    new_num_updates = train_state.num_updates + 1\n",
    "    key, subkey = jax.random.split(key)\n",
    "    new_model_state, new_component_adapter_state, new_sample_db_state = \\\n",
    "        gmm_network.component_adapter(train_state.component_adaptation_state,\n",
    "                                                    new_sample_db_state,\n",
    "                                                    new_model_state,\n",
    "                                                    new_num_updates,\n",
    "                                                    subkey)\n",
    "    return GMMTrainingState(temperature=train_state.temperature,\n",
    "                        model_state=new_model_state,\n",
    "                        component_adaptation_state=new_component_adapter_state,\n",
    "                        num_updates=new_num_updates,\n",
    "                        sample_db_state=new_sample_db_state,\n",
    "                        weight_stepsize=train_state.weight_stepsize)\n",
    "def eval(seed: chex.Array, train_state: GMMTrainingState, target_log_prob_fn, n_eval_samples, target_samples=None):\n",
    "    samples = gmm_network.model.sample(train_state.model_state.gmm_state, seed, n_eval_samples)[0]\n",
    "    def log_prob_model_fn(sample):\n",
    "        log_prob = jax.vmap(functools.partial(gmm_network.model.log_density, gmm_state=train_state.model_state.gmm_state))(sample=sample)\n",
    "        bijector_log_prob = lambda x : jnp.log(2 * jnp.ones_like(low)).sum(-1) -jnp.log(high-low).sum(-1)-jnp.log(1- ((2*x-(low+high))/(high-low))**2).sum(-1)\n",
    "        return log_prob #- bijector_log_prob(sample)\n",
    "    log_prob_model = log_prob_model_fn(sample=samples)\n",
    "    log_prob_target = jax.vmap(target_log_prob_fn)(samples)\n",
    "    log_ratio = log_prob_target - log_prob_model\n",
    "    if target_samples is not None:\n",
    "        fwd_log_prob_model = jax.vmap(gmm_network.model.log_density, in_axes=(None, 0))(train_state.model_state.gmm_state, target_samples)\n",
    "        fwd_log_prob_target = jax.vmap(target_log_prob_fn)(target_samples)\n",
    "        fwd_log_ratio = fwd_log_prob_target - fwd_log_prob_model\n",
    "    else:\n",
    "        fwd_log_ratio = None\n",
    "\n",
    "    return samples, log_ratio, log_prob_target, fwd_log_ratio, n_eval_samples, log_prob_model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "logger = {\n",
    "    'KL/elbo': [],\n",
    "    'KL/eubo': [],\n",
    "    'logZ/delta_forward': [],\n",
    "    'logZ/forward': [],\n",
    "    'logZ/delta_reverse': [],\n",
    "    'logZ/reverse': [],\n",
    "    'ESS/forward': [],\n",
    "    'ESS/reverse': [],\n",
    "    'num_components' : [],\n",
    "}\n",
    "def compute_reverse_ess(log_weights, eval_samples):\n",
    "    # Subtract the maximum log weight for numerical stability\n",
    "    max_log_weight = jnp.max(log_weights)\n",
    "    stable_log_weights = log_weights - max_log_weight\n",
    "\n",
    "    # Compute the importance weights in a numerically stable way\n",
    "    is_weights = jnp.exp(stable_log_weights)\n",
    "\n",
    "    # Compute the sums needed for ESS\n",
    "    sum_is_weights = jnp.sum(is_weights)\n",
    "    sum_is_weights_squared = jnp.sum(is_weights ** 2)\n",
    "\n",
    "    # Calculate the effective sample size (ESS)\n",
    "    ess = (sum_is_weights ** 2) / (eval_samples * sum_is_weights_squared)\n",
    "\n",
    "    return ess\n",
    "def eval_fn(samples, log_ratio, target_log_prob, fwd_log_ratio, n_eval_samples, model_log_prob_fn):\n",
    "    ln_z = jax.nn.logsumexp(log_ratio) - jnp.log(n_eval_samples)\n",
    "    elbo = jnp.mean(log_ratio)\n",
    "\n",
    "    if target.log_Z is not None:\n",
    "        logger['logZ/delta_reverse'].append(jnp.abs(ln_z - target.log_Z))\n",
    "\n",
    "    logger['logZ/reverse'].append(ln_z)\n",
    "    logger['KL/elbo'].append(elbo)\n",
    "    logger['ESS/reverse'].append(compute_reverse_ess(log_ratio, n_eval_samples))\n",
    "    # logger['other/target_log_prob'].append(jnp.mean(target_log_prob))\n",
    "\n",
    "    if fwd_log_ratio is not None:\n",
    "        eubo = jnp.mean(fwd_log_ratio)\n",
    "        fwd_ln_z = - (jax.scipy.special.logsumexp(-fwd_log_ratio) - jnp.log(n_eval_samples))\n",
    "        fwd_ess = jnp.exp(fwd_ln_z - (jax.scipy.special.logsumexp(fwd_log_ratio) - jnp.log(n_eval_samples)))\n",
    "\n",
    "        if target.log_Z is not None:\n",
    "            logger['logZ/delta_forward'].append(jnp.abs(fwd_ln_z - target.log_Z))\n",
    "        logger['logZ/forward'].append(fwd_ln_z)\n",
    "        logger['KL/eubo'].append(eubo)\n",
    "        logger['ESS/forward'].append(fwd_ess)\n",
    "    # if dim==2:\n",
    "    #     logger.update(target.visualise(samples=samples, model_log_prob_fn=model_log_prob_fn ,show=True))\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 5000\n",
    "seed = 23\n",
    "eval_freq = 10\n",
    "n_eval_samples= 10000\n",
    "target_samples = target.sample(jax.random.PRNGKey(0), (n_eval_samples,))\n",
    "# target_log_prob = jax.jit(lambda x : target.log_prob(x))\n",
    "rng =jax.random.PRNGKey(seed)\n",
    "key, rng = jax.random.split(rng)\n",
    "timer = 0\n",
    "state = initial_train_state\n",
    "\n",
    "def _train(carry, _):\n",
    "    state, key = carry\n",
    "    key, subkey = jax.random.split(key)\n",
    "    state = train_iter(state, subkey, target.log_prob)\n",
    "    return (state, key), _\n",
    "def jitted_train(state, key):\n",
    "    (state, _), _ = jax.lax.scan(_train, (state, key), (), length=eval_freq)\n",
    "    return state\n",
    "# jax.config.update(\"jax_disable_jit\", True) \n",
    "assert iterations % eval_freq == 0\n",
    "num_eval_calls = iterations // eval_freq\n",
    "for _ in range(batch_size//num_envs):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    state = gather_samples(state, subkey, target.log_prob)\n",
    "global_step = 0\n",
    "for _ in range(num_eval_calls):\n",
    "    iter_time = time()\n",
    "    key, subkey = jax.random.split(key)\n",
    "    \n",
    "    state = train_iter(state, subkey, target.log_prob)\n",
    "    # (state, _), _ = jax.lax.scan(_train, (state, subkey), (), length=eval_freq)\n",
    "    # step+=1\n",
    "    timer += time() - iter_time\n",
    "    key, subkey = jax.random.split(key)\n",
    "    logger = eval_fn(*eval(subkey, state, target.log_prob, n_eval_samples, target_samples))\n",
    "    # logger['stats/num_samples'] = [state.sample_db_state.num_samples_written]\n",
    "    # logger['stats/num_components'] = [state.model_state.gmm_state.num_components]\n",
    "\n",
    "    # print(f\"{_*eval_freq}/{iterations}: \"\n",
    "    #         f\"The model now has {state.model_state.gmm_state.num_components} components \")\n",
    "    logger['num_components'].append(int(state.model_state.gmm_state.num_components))\n",
    "plt.plot(logger['KL/eubo'], label='KL/eubo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(logger['KL/elbo'], label='KL/elbo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "plt.plot(logger['num_components'], label='num_components')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "del logger['KL/eubo']\n",
    "del logger['KL/elbo']\n",
    "del logger['num_components']\n",
    "for k, v in logger.items():\n",
    "    plt.plot(v, label=k)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
